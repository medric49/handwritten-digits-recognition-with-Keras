{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labwork on recoginition of digits by a Neural Network\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The purpose of this exercise is to give an example of the use of neural networks. We'll use neural networks to create a system capable of recognizing handwritten digits. The general functionality of said system consists of the following:\n",
    "- An input (in this case, our handwritten digits)\n",
    "- The hidden layers, which will work towards the recognition of a given digit\n",
    "- The output, which will be a digit between 0 and 9\n",
    "\n",
    "\n",
    "In this labwork, we will use 3 tools.\n",
    "* **Keras** :\n",
    "To build our neural networks.\n",
    "* **Numpy** :\n",
    "To manage vector and matrix easily.\n",
    "* **Matplotlib** :\n",
    "To plot images and graphs in order to illustrate our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TiyE8ymsOKdz"
   },
   "source": [
    "## Preliminaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ta9Jj9RCO-zS"
   },
   "source": [
    "### Importation of libraries\n",
    "\n",
    "Our first step, as in all Python code, is to import the necessary libraries for the exercise. We'll use TensorFlow 1.14 for it to be compatible with our current version of Keras, which supports all of the methods we need. We'll also import varios Keras components, like models, layer, and optimizers.\n",
    "\n",
    "Finally, we'll include the library that's never missing in model creation: numpy. Numpy includes various mathematical methods required for ML and NN development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "q1RGWOI0O_le",
    "outputId": "84b52271-35bb-4019-eb1b-9faef1542f83"
   },
   "outputs": [],
   "source": [
    "import keras.models as models\n",
    "import keras.layers as layers\n",
    "import keras.optimizers as optimizers\n",
    "import keras.metrics as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Tcq2_sCPIOR"
   },
   "source": [
    "### Loading of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_Mi_bXgQFd0"
   },
   "source": [
    "Secondly, we'll do our next essential step: the inclusion of data. As we had already learned in the course before, the MINST dataset was compiled throughout the years by Yann LeCun, Corinna Cortes, and Christopher J.C. Burges, and provides us with thousands of samples of handwritten digits, which can be used to train and test our models. \n",
    "\n",
    "The inclusion of this dataset is very simple, as we're only required to import \"mnist\" from Keras' datasets module. \n",
    "\n",
    "Here's also an important detail: we're going to be using different datasets to train and to test our model. The cause of this has already been explained in our course, but just to review, we're doing this to stop our model from overfitting the training dataset. If we used a single dataset to both train and test, we'd end up with a model that has a very low error rate for said set, but a much higher one for others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "RhaYHJn7PYB7",
    "outputId": "91250fa8-e2b2-4488-be43-9712ac917d71"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, y_train, x_test, y_test = np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rAkkSVv5WYyQ"
   },
   "source": [
    "Here, we simply use matplotlib for visual representation. In this case, we're using it to display a digit from our dataset, which is represented as a 28 x 28 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "UvrGrGHHPcLm",
    "outputId": "f1e853b2-c0c3-4e68-bc68-89035275800d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(x_train[18], cmap=\"Greys_r\")\n",
    "print(y_train[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xbx5h0pQ-tT"
   },
   "source": [
    "For the following step, we have to notice something: the data that we're using for images is, naturally, represented by a matrix. Said matrix has a total of 784 pixels, and each pixel is represented by a number from 0 to 1. However, this number is not a probability, as it usually is in other ML/NN exercices. \n",
    "\n",
    "This time around, this number from 0 to 1 represents the color of the current pixel. 0 means that the pixel is completely black (hexadecimal code #000000), while 1 represents a white pixel (#FFFFFF).\n",
    "\n",
    "Now that we know this, we have to remember that we can't use matrices as inputs for a neural network. At least, not in their \"actual\" matrix state. Instead of using a whole 28x28 matrix as an input, we'll convert this into an array of 748 elements, which will have the range of values we already talked about above. \n",
    "\n",
    "As we can see below, we're doing this for both the training and the test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyYO4zP4Phnm"
   },
   "outputs": [],
   "source": [
    "range_ = range(10)\n",
    "x_train_d = x_train.reshape((x_train.shape[0], -1))\n",
    "x_test_d = x_test.reshape((x_test.shape[0], -1))\n",
    "y_train_d = np.array( [ [ 0 if i!=r else 1 for i in range_ ] for r in y_train ])\n",
    "y_test_d = np.array( [ [ 0 if i!=r else 1 for i in range_ ] for r in y_test ])\n",
    "\n",
    "n_input = x_train_d.shape[1] #784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MlK9UYbRY83"
   },
   "source": [
    "### Plotting\n",
    "\n",
    "Now, we're going to do a little bit of plotting. This does not affect the functionality of our neural network in general, but it will help us evaluate the results more easily, by giving us a visual representation of them.\n",
    "\n",
    "In this case, we're using a bar chart to represent the probability of a given handwritten digit belonging to one class or the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rX7PWK5_RbME"
   },
   "outputs": [],
   "source": [
    "def show_prediction(data, img) :\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(121)\n",
    "    tick_label = ['{}'.format(i) for i in range(10)]\n",
    "    plt.bar(tick_label, data)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img, cmap=\"Greys_r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "9XsF45MlRdaN",
    "outputId": "7d494947-efd8-48b5-af50-39845ef03dd7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_prediction(np.array([0, 0, 0.75, 0.25, 0, 0, 0, 0, 0, 0]), x_train[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GkQv51CSGWY"
   },
   "source": [
    "## Neural network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AI833-JoUm_x"
   },
   "source": [
    "### Creation of the model\n",
    "\n",
    "Here comes the most interesting part. We have our datasets, we have our input, and we have our plotting. Now, it's time to create our model. We'll explain more in depth all of our models components in our practical report. \n",
    "\n",
    "For now, let's remark how easy it is to build a model with Keras: it all consists in a pretty simple process in which we add all of our layers and set up some parameters like dropout or the activation function(s) we're giong to use. \n",
    "\n",
    "Our first architecture is made of a sequence of\n",
    "* **a Full connected layer with input size = 784 and output size =  400, ending with relu activation**\n",
    "* **a batch normalization layer**\n",
    "* **a Dropout layer**\n",
    "\n",
    "\n",
    "* **a Full connected layer with input size = 400 and output size = 64, ending with relu activation**\n",
    "* **a batch normalization**\n",
    "* **a Dropout layer**\n",
    "\n",
    "\n",
    "* **a Full connected layer with input size = 64 and output size = 10, ending with softmax activation**\n",
    "\n",
    "So we have a full connected neural network with this architecture : **784 -> 400 -> 64 -> 10**  \n",
    "The activation function used in the hidden layers is **ReLU**,  \n",
    "$ ReLU(z) = max(0,z)$  \n",
    "And the activation function of the output layer is **softmax**  \n",
    "$ softmax(z_i) = \\frac{ e^{z_i}}{ \\sum_j{ e^{z_j} } }$\n",
    "\n",
    "We add in this architecture dropout layers with probability of **0.2**. These layers will help our Network to avoid overfitting effects by cancelling, with a probability of 0.2, some neuron effect during a turn of training.\n",
    "\n",
    "The normalization is layer is used to contract output between -1 and 1, in order to make sure that the variance of parameters is not high. The reason for that is that, if parameters are too divergent, it will create an overfitting effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3FH3jI2SLdg"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "dropout = 0.2\n",
    "\n",
    "n_layer_1 = 400\n",
    "n_layer_2 = 64\n",
    "\n",
    "lr = 0.02\n",
    "\n",
    "model.add(layers.Dense(n_layer_1, input_dim=n_input, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Dense(n_layer_2, input_dim=n_layer_1, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Dense(10, input_dim=n_layer_2, activation=\"softmax\"))\n",
    "\n",
    "optimizer = optimizers.SGD(lr=lr)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fr-1Lj9GAnTl"
   },
   "source": [
    "The optimization method we use for this method is SGD, and the learning rate chosen is 0.02. And then, we have chosen as loss function, the cross entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6o-EREEUji-"
   },
   "source": [
    "#### Training of the model\n",
    "\n",
    "As the subtitle implies, it's time to train our model. For this, we'll choose the number of epochs we'd like to run (40, in our case), the size of our data batches, and our validation split (0.15, then the validation data is taken from the training data, and it is 15% of the original training data). \n",
    "And to finish, our training data will be split into batch of 32.\n",
    "These parameters are preliminary and we'll play around with them in the following examples, to compare the results we get with different parameteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "colab_type": "code",
    "id": "GY-M6b_mSO7b",
    "outputId": "53aed504-ffc9-40d9-cf4c-51c51785fb95",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51000 samples, validate on 9000 samples\n",
      "Epoch 1/40\n",
      "51000/51000 [==============================] - 14s 266us/step - loss: 0.3825 - accuracy: 0.8852 - val_loss: 0.1557 - val_accuracy: 0.9594\n",
      "Epoch 2/40\n",
      "51000/51000 [==============================] - 14s 265us/step - loss: 0.2096 - accuracy: 0.9366 - val_loss: 0.1307 - val_accuracy: 0.9692\n",
      "Epoch 3/40\n",
      "51000/51000 [==============================] - 14s 276us/step - loss: 0.1657 - accuracy: 0.9503 - val_loss: 0.1250 - val_accuracy: 0.9696\n",
      "Epoch 4/40\n",
      "51000/51000 [==============================] - 14s 267us/step - loss: 0.1435 - accuracy: 0.9561 - val_loss: 0.1134 - val_accuracy: 0.9737\n",
      "Epoch 5/40\n",
      "51000/51000 [==============================] - 13s 255us/step - loss: 0.1292 - accuracy: 0.9603 - val_loss: 0.1090 - val_accuracy: 0.9746\n",
      "Epoch 6/40\n",
      "51000/51000 [==============================] - 13s 262us/step - loss: 0.1174 - accuracy: 0.9629 - val_loss: 0.1084 - val_accuracy: 0.9758\n",
      "Epoch 7/40\n",
      "51000/51000 [==============================] - 14s 281us/step - loss: 0.1053 - accuracy: 0.9674 - val_loss: 0.1110 - val_accuracy: 0.9770\n",
      "Epoch 8/40\n",
      "51000/51000 [==============================] - 14s 272us/step - loss: 0.1002 - accuracy: 0.9683 - val_loss: 0.1017 - val_accuracy: 0.9782\n",
      "Epoch 9/40\n",
      "51000/51000 [==============================] - 14s 279us/step - loss: 0.0917 - accuracy: 0.9708 - val_loss: 0.1099 - val_accuracy: 0.9789\n",
      "Epoch 10/40\n",
      "51000/51000 [==============================] - 14s 265us/step - loss: 0.0856 - accuracy: 0.9730 - val_loss: 0.1152 - val_accuracy: 0.9794\n",
      "Epoch 11/40\n",
      "51000/51000 [==============================] - 13s 263us/step - loss: 0.0796 - accuracy: 0.9744 - val_loss: 0.1086 - val_accuracy: 0.9777\n",
      "Epoch 12/40\n",
      "51000/51000 [==============================] - 13s 264us/step - loss: 0.0772 - accuracy: 0.9754 - val_loss: 0.0912 - val_accuracy: 0.9797\n",
      "Epoch 13/40\n",
      "51000/51000 [==============================] - 14s 266us/step - loss: 0.0746 - accuracy: 0.9755 - val_loss: 0.1105 - val_accuracy: 0.9796\n",
      "Epoch 14/40\n",
      "51000/51000 [==============================] - 14s 265us/step - loss: 0.0687 - accuracy: 0.9787 - val_loss: 0.1109 - val_accuracy: 0.9808\n",
      "Epoch 15/40\n",
      "51000/51000 [==============================] - 13s 262us/step - loss: 0.0636 - accuracy: 0.9796 - val_loss: 0.1153 - val_accuracy: 0.9801\n",
      "Epoch 16/40\n",
      "51000/51000 [==============================] - 14s 273us/step - loss: 0.0597 - accuracy: 0.9805 - val_loss: 0.1052 - val_accuracy: 0.9792\n",
      "Epoch 17/40\n",
      "51000/51000 [==============================] - 13s 262us/step - loss: 0.0577 - accuracy: 0.9815 - val_loss: 0.1199 - val_accuracy: 0.9792\n",
      "Epoch 18/40\n",
      "51000/51000 [==============================] - 13s 261us/step - loss: 0.0574 - accuracy: 0.9812 - val_loss: 0.1293 - val_accuracy: 0.9794\n",
      "Epoch 19/40\n",
      "51000/51000 [==============================] - 13s 264us/step - loss: 0.0573 - accuracy: 0.9812 - val_loss: 0.1149 - val_accuracy: 0.9783\n",
      "Epoch 20/40\n",
      "51000/51000 [==============================] - 13s 263us/step - loss: 0.0569 - accuracy: 0.9815 - val_loss: 0.1148 - val_accuracy: 0.9800\n",
      "Epoch 21/40\n",
      "51000/51000 [==============================] - 13s 259us/step - loss: 0.0540 - accuracy: 0.9821 - val_loss: 0.1255 - val_accuracy: 0.9811\n",
      "Epoch 22/40\n",
      "51000/51000 [==============================] - 13s 257us/step - loss: 0.0537 - accuracy: 0.9826 - val_loss: 0.1266 - val_accuracy: 0.9802\n",
      "Epoch 23/40\n",
      "51000/51000 [==============================] - 13s 255us/step - loss: 0.0502 - accuracy: 0.9840 - val_loss: 0.1181 - val_accuracy: 0.9817\n",
      "Epoch 24/40\n",
      "51000/51000 [==============================] - 13s 256us/step - loss: 0.0483 - accuracy: 0.9839 - val_loss: 0.1410 - val_accuracy: 0.9803\n",
      "Epoch 25/40\n",
      "51000/51000 [==============================] - 13s 259us/step - loss: 0.0482 - accuracy: 0.9837 - val_loss: 0.1118 - val_accuracy: 0.9809\n",
      "Epoch 26/40\n",
      "51000/51000 [==============================] - 13s 257us/step - loss: 0.0527 - accuracy: 0.9828 - val_loss: 0.1143 - val_accuracy: 0.9812\n",
      "Epoch 27/40\n",
      "51000/51000 [==============================] - 13s 258us/step - loss: 0.0447 - accuracy: 0.9851 - val_loss: 0.1416 - val_accuracy: 0.9824\n",
      "Epoch 28/40\n",
      "51000/51000 [==============================] - 13s 261us/step - loss: 0.0481 - accuracy: 0.9837 - val_loss: 0.1331 - val_accuracy: 0.9812\n",
      "Epoch 29/40\n",
      "51000/51000 [==============================] - 14s 272us/step - loss: 0.0448 - accuracy: 0.9852 - val_loss: 0.1371 - val_accuracy: 0.9811\n",
      "Epoch 30/40\n",
      "51000/51000 [==============================] - 15s 286us/step - loss: 0.0437 - accuracy: 0.9854 - val_loss: 0.1500 - val_accuracy: 0.9812\n",
      "Epoch 31/40\n",
      "51000/51000 [==============================] - 15s 294us/step - loss: 0.0427 - accuracy: 0.9855 - val_loss: 0.1709 - val_accuracy: 0.9819\n",
      "Epoch 32/40\n",
      "51000/51000 [==============================] - 14s 276us/step - loss: 0.0406 - accuracy: 0.9865 - val_loss: 0.1462 - val_accuracy: 0.9826\n",
      "Epoch 33/40\n",
      "51000/51000 [==============================] - 14s 271us/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.1717 - val_accuracy: 0.9816\n",
      "Epoch 34/40\n",
      "51000/51000 [==============================] - 14s 273us/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 0.2013 - val_accuracy: 0.9814\n",
      "Epoch 35/40\n",
      "51000/51000 [==============================] - 13s 256us/step - loss: 0.0387 - accuracy: 0.9873 - val_loss: 0.1884 - val_accuracy: 0.9818\n",
      "Epoch 36/40\n",
      "51000/51000 [==============================] - 14s 267us/step - loss: 0.0357 - accuracy: 0.9876 - val_loss: 0.2066 - val_accuracy: 0.9812\n",
      "Epoch 37/40\n",
      "51000/51000 [==============================] - 14s 267us/step - loss: 0.0392 - accuracy: 0.9865 - val_loss: 0.1855 - val_accuracy: 0.9821\n",
      "Epoch 38/40\n",
      "51000/51000 [==============================] - 14s 268us/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 0.1834 - val_accuracy: 0.9812\n",
      "Epoch 39/40\n",
      "51000/51000 [==============================] - 13s 258us/step - loss: 0.0375 - accuracy: 0.9871 - val_loss: 0.1502 - val_accuracy: 0.9818\n",
      "Epoch 40/40\n",
      "51000/51000 [==============================] - 14s 267us/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 0.1896 - val_accuracy: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f72e867ed68>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_d, y_train_d, epochs=40, batch_size=32, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explaination of the learning procedure\n",
    "\n",
    "The learning is done in **40 turns (the number of epochs)**, during which the model will ameliorate its parameters (weights and bias) by a **schochastic gradient descent optimization**.\n",
    "\n",
    "Before the learning, the original training data is split into 2 batchs, the learning data batch and the validation data batch. **The validation data batch is 20% of the original learning data**.\n",
    "And then, during the learning, the new learning data batch is split into **batches of size 32**, in order to facilitate the learning and make it faster. The loss is computed for each batch, by a **cross entropy loss function**, after a mean error is computed.\n",
    "\n",
    "Having the final error, a backpropagation algorithm is executed and at the end all the parameters are upgraded by a **SGD optimizer**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZeIDuhXU9sk"
   },
   "source": [
    "#### Evaluation of the model\n",
    "\n",
    "Last, but not least, we're going to see how good our model is. This process is very simply and, in Keras, can be done with a single line of code. We just have to call the evaluate() method and select the test data we'll be using for the evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "6T255ojUVAQ_",
    "outputId": "04e91992-2fa5-4c06-e5fe-ff8d818e47de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 102us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10896185940111172, 0.9814000129699707]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_d, y_test_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-Dz8zVlDei6"
   },
   "source": [
    "After training, our model obtains **a success rate of 98.14%**. It does not seem terrible, but when compared to the state-of-the art for MNIST, it could be much better. Later on this document, we'll play our hyperparameters and try new architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLp9iyiyVIoF"
   },
   "source": [
    "#### Visualization \n",
    "\n",
    "Again, to demonstrate how our model works, we'll use a digit from our dataset and see what is predicted for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "rOLgUgGGVTrQ",
    "outputId": "456645ad-c600-498f-ae57-9e477f428308"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 2262\n",
    "show_prediction(result[n], x_test[n] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 : Let's try with convolutional neural network !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that a full connected neural network is limited, now we will try to recognize digits by using a convolutional neural network. The architecture of our network is the following :\n",
    "\n",
    "* A convolutional layer with 32 filters and a kernel of size 3x3, using ReLU\n",
    "* A batch normalization layer\n",
    "* A convolutional layer with 32 filters and a kernel of size 3x3, using ReLU\n",
    "* A batch normalization layer\n",
    "* A Convolutional layer with 32 filters and a kernel of size 5x5, using ReLU\n",
    "* A batch normalization layer\n",
    "* A dropout layer\n",
    "* A Convolutional layer with 64 filters and a kernel of size 3x3, using ReLU\n",
    "* A batch normalization layer\n",
    "* A Convolutional layer with 64 filters and a kernel of size 3x3, using ReLU\n",
    "* A batch normalization layer\n",
    "* A Convolutional layer with 64 filters and a kernel of size 5x5, using ReLU\n",
    "* A batch normalization layer\n",
    "* A dropout layer\n",
    "* A Convolutional layer with 128 filters and a kernel of size 3x3, using ReLU\n",
    "* A batch normalization layer\n",
    "* A dropout layer\n",
    "* A full connected layer of output size = 10, using softmax activation\n",
    "\n",
    "Our **learning rate is 0.02**, optimized by **SGD procedure**, and our **loss function is the cross entropy**.   \n",
    "ReLU proved recently it's a good choice, so we choose **ReLU** as activation function in the hidden layers.  \n",
    "And the activation function of the output layer is **softmax**.  \n",
    "\n",
    "Because of the high number of neurons, we will increase the **dropout probability to 0.4** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = models.Sequential()\n",
    "dropout3 = 0.4\n",
    "\n",
    "model3.add(layers.Conv2D(32, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model3.add(layers.BatchNormalization())\n",
    "\n",
    "model3.add(layers.Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model3.add(layers.BatchNormalization())\n",
    "\n",
    "model3.add(layers.Conv2D(32, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
    "model3.add(layers.BatchNormalization())\n",
    "\n",
    "model3.add(layers.Dropout(dropout3))\n",
    "\n",
    "model3.add(layers.Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.Dropout(dropout3))\n",
    "\n",
    "model3.add(layers.Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dropout(dropout3))\n",
    "model3.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer3 = optimizers.SGD(lr=0.02)\n",
    "model3.compile(loss=\"categorical_crossentropy\", optimizer=optimizer3, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train this model. We will run the training with only **20 epochs**, because this model is very complex, and I love my computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_conv = x_train.reshape((-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "51000/51000 [==============================] - 238s 5ms/step - loss: 0.2068 - accuracy: 0.9359 - val_loss: 0.0474 - val_accuracy: 0.9853\n",
      "Epoch 2/20\n",
      "51000/51000 [==============================] - 226s 4ms/step - loss: 0.0780 - accuracy: 0.9764 - val_loss: 0.0339 - val_accuracy: 0.9901\n",
      "Epoch 3/20\n",
      "51000/51000 [==============================] - 221s 4ms/step - loss: 0.0593 - accuracy: 0.9819 - val_loss: 0.0298 - val_accuracy: 0.9921\n",
      "Epoch 4/20\n",
      "51000/51000 [==============================] - 221s 4ms/step - loss: 0.0505 - accuracy: 0.9845 - val_loss: 0.0276 - val_accuracy: 0.9929\n",
      "Epoch 5/20\n",
      "51000/51000 [==============================] - 219s 4ms/step - loss: 0.0451 - accuracy: 0.9861 - val_loss: 0.0381 - val_accuracy: 0.9889\n",
      "Epoch 6/20\n",
      "51000/51000 [==============================] - 209s 4ms/step - loss: 0.0385 - accuracy: 0.9881 - val_loss: 0.0262 - val_accuracy: 0.9931\n",
      "Epoch 7/20\n",
      "51000/51000 [==============================] - 215s 4ms/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
      "Epoch 8/20\n",
      "51000/51000 [==============================] - 211s 4ms/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.0240 - val_accuracy: 0.9938\n",
      "Epoch 9/20\n",
      "51000/51000 [==============================] - 213s 4ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.0266 - val_accuracy: 0.9924\n",
      "Epoch 10/20\n",
      "51000/51000 [==============================] - 211s 4ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.0236 - val_accuracy: 0.9940\n",
      "Epoch 11/20\n",
      "51000/51000 [==============================] - 215s 4ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.0238 - val_accuracy: 0.9933\n",
      "Epoch 12/20\n",
      "51000/51000 [==============================] - 211s 4ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.0230 - val_accuracy: 0.9942\n",
      "Epoch 13/20\n",
      "51000/51000 [==============================] - 210s 4ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.0209 - val_accuracy: 0.9947\n",
      "Epoch 14/20\n",
      "51000/51000 [==============================] - 209s 4ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 0.0237 - val_accuracy: 0.9939\n",
      "Epoch 15/20\n",
      "51000/51000 [==============================] - 208s 4ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0230 - val_accuracy: 0.9943\n",
      "Epoch 16/20\n",
      "51000/51000 [==============================] - 207s 4ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.0220 - val_accuracy: 0.9942\n",
      "Epoch 17/20\n",
      "51000/51000 [==============================] - 207s 4ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.0209 - val_accuracy: 0.9946\n",
      "Epoch 18/20\n",
      "51000/51000 [==============================] - 207s 4ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0237 - val_accuracy: 0.9938\n",
      "Epoch 19/20\n",
      "51000/51000 [==============================] - 228s 4ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.0241 - val_accuracy: 0.9941\n",
      "Epoch 20/20\n",
      "51000/51000 [==============================] - 251s 5ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.0244 - val_accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fbf0846b7b8>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train_conv, y_train_d, epochs=20, batch_size=32, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "Just like before, we will evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_conv = x_test.reshape((-1, 28,28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 12s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.015301902328125288, 0.9957000017166138]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x_test_conv, y_test_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great ! We obtain **an accuracy of 99.57%** on the test data batch. It means that convolutional architecture is really better than the previous architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "SIRR - Handwritten digit recognition",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.22.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
